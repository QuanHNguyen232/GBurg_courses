{"backend_state":"ready","kernel":"python3","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":83005440},"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"type":"settings"}
{"cell_type":"code","exec_count":116,"id":"540d34","input":"# Imports\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nfrom sklearn.preprocessing import StandardScaler\nimport umap\n","pos":1,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":2,"id":"3e1971","input":"# Imports\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\n\nimport matplotlib.pyplot as plt\nimport matplotlib.mlab as mlab\nimport matplotlib\nplt.style.use('ggplot')\nfrom matplotlib.pyplot import figure\n\n%matplotlib inline\nmatplotlib.rcParams['figure.figsize'] = (12,8)\n\npd.options.mode.chained_assignment = None\n\n# Load housing data\n\ndf = pd.read_csv('http://cs.gettysburg.edu/~tneller/ds256/data/missing/sberbank.csv')\ndf.head()","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>timestamp</th>\n      <th>full_sq</th>\n      <th>life_sq</th>\n      <th>floor</th>\n      <th>max_floor</th>\n      <th>material</th>\n      <th>build_year</th>\n      <th>num_room</th>\n      <th>kitch_sq</th>\n      <th>...</th>\n      <th>cafe_count_5000_price_2500</th>\n      <th>cafe_count_5000_price_4000</th>\n      <th>cafe_count_5000_price_high</th>\n      <th>big_church_count_5000</th>\n      <th>church_count_5000</th>\n      <th>mosque_count_5000</th>\n      <th>leisure_count_5000</th>\n      <th>sport_count_5000</th>\n      <th>market_count_5000</th>\n      <th>price_doc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2011-08-20</td>\n      <td>43</td>\n      <td>27.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>9</td>\n      <td>4</td>\n      <td>0</td>\n      <td>13</td>\n      <td>22</td>\n      <td>1</td>\n      <td>0</td>\n      <td>52</td>\n      <td>4</td>\n      <td>5850000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2011-08-23</td>\n      <td>34</td>\n      <td>19.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>15</td>\n      <td>3</td>\n      <td>0</td>\n      <td>15</td>\n      <td>29</td>\n      <td>1</td>\n      <td>10</td>\n      <td>66</td>\n      <td>14</td>\n      <td>6000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>2011-08-27</td>\n      <td>43</td>\n      <td>29.0</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>10</td>\n      <td>3</td>\n      <td>0</td>\n      <td>11</td>\n      <td>27</td>\n      <td>0</td>\n      <td>4</td>\n      <td>67</td>\n      <td>10</td>\n      <td>5700000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>2011-09-01</td>\n      <td>89</td>\n      <td>50.0</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>11</td>\n      <td>2</td>\n      <td>1</td>\n      <td>4</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>26</td>\n      <td>3</td>\n      <td>13100000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>2011-09-05</td>\n      <td>77</td>\n      <td>77.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>319</td>\n      <td>108</td>\n      <td>17</td>\n      <td>135</td>\n      <td>236</td>\n      <td>2</td>\n      <td>91</td>\n      <td>195</td>\n      <td>14</td>\n      <td>16331452</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 292 columns</p>\n</div>","text/plain":"   id   timestamp  full_sq  life_sq  floor  max_floor  material  build_year  \\\n0   1  2011-08-20       43     27.0    4.0        NaN       NaN         NaN   \n1   2  2011-08-23       34     19.0    3.0        NaN       NaN         NaN   \n2   3  2011-08-27       43     29.0    2.0        NaN       NaN         NaN   \n3   4  2011-09-01       89     50.0    9.0        NaN       NaN         NaN   \n4   5  2011-09-05       77     77.0    4.0        NaN       NaN         NaN   \n\n   num_room  kitch_sq  ...  cafe_count_5000_price_2500  \\\n0       NaN       NaN  ...                           9   \n1       NaN       NaN  ...                          15   \n2       NaN       NaN  ...                          10   \n3       NaN       NaN  ...                          11   \n4       NaN       NaN  ...                         319   \n\n  cafe_count_5000_price_4000 cafe_count_5000_price_high  \\\n0                          4                          0   \n1                          3                          0   \n2                          3                          0   \n3                          2                          1   \n4                        108                         17   \n\n   big_church_count_5000  church_count_5000  mosque_count_5000  \\\n0                     13                 22                  1   \n1                     15                 29                  1   \n2                     11                 27                  0   \n3                      4                  4                  0   \n4                    135                236                  2   \n\n   leisure_count_5000  sport_count_5000  market_count_5000  price_doc  \n0                   0                52                  4    5850000  \n1                  10                66                 14    6000000  \n2                   4                67                 10    5700000  \n3                   0                26                  3   13100000  \n4                  91               195                 14   16331452  \n\n[5 rows x 292 columns]"},"exec_count":2,"output_type":"execute_result"}},"pos":3,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":34,"id":"7c07fd","input":"df = pd.read_csv('http://cs.gettysburg.edu/~tneller/ds256/data/missing/sullivan_property_data.csv')\ndf","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PID</th>\n      <th>ST_NUM</th>\n      <th>ST_NAME</th>\n      <th>OWN_OCCUPIED</th>\n      <th>NUM_BEDROOMS</th>\n      <th>NUM_BATH</th>\n      <th>SQ_FT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100001000.0</td>\n      <td>104.0</td>\n      <td>PUTNAM</td>\n      <td>Y</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100002000.0</td>\n      <td>197.0</td>\n      <td>LEXINGTON</td>\n      <td>N</td>\n      <td>3</td>\n      <td>1.5</td>\n      <td>--</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100003000.0</td>\n      <td>NaN</td>\n      <td>LEXINGTON</td>\n      <td>N</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>850</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100004000.0</td>\n      <td>201.0</td>\n      <td>BERKELEY</td>\n      <td>12</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>700</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>203.0</td>\n      <td>BERKELEY</td>\n      <td>Y</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1600</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>100006000.0</td>\n      <td>207.0</td>\n      <td>BERKELEY</td>\n      <td>Y</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>800</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>100007000.0</td>\n      <td>NaN</td>\n      <td>WASHINGTON</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>HURLEY</td>\n      <td>950</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>100008000.0</td>\n      <td>213.0</td>\n      <td>TREMONT</td>\n      <td>Y</td>\n      <td>--</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>100009000.0</td>\n      <td>215.0</td>\n      <td>TREMONT</td>\n      <td>Y</td>\n      <td>na</td>\n      <td>2</td>\n      <td>1800</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"           PID  ST_NUM     ST_NAME OWN_OCCUPIED NUM_BEDROOMS NUM_BATH SQ_FT\n0  100001000.0   104.0      PUTNAM            Y            3        1  1000\n1  100002000.0   197.0   LEXINGTON            N            3      1.5    --\n2  100003000.0     NaN   LEXINGTON            N          NaN        1   850\n3  100004000.0   201.0    BERKELEY           12            1      NaN   700\n4          NaN   203.0    BERKELEY            Y            3        2  1600\n5  100006000.0   207.0    BERKELEY            Y          NaN        1   800\n6  100007000.0     NaN  WASHINGTON          NaN            2   HURLEY   950\n7  100008000.0   213.0     TREMONT            Y           --        1   NaN\n8  100009000.0   215.0     TREMONT            Y           na        2  1800"},"exec_count":34,"output_type":"execute_result"}},"pos":6,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"288224","input":"(end of homework)","pos":12,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"4aba38","input":"# Data Cleaning: Missing Values\n\nLearning Objectives:\n* Students will learn to identify and make a common representation for missing values.\n* Students will gain further practice in dropping rows and/or columns with missing values.\n* Students will learn simple imputation of missing values.\n\nReadings before class:\n* Review: Jake VanderPlas. [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/):\n  * [Chapter 3 section \"Handling Missing Data\"](https://jakevdp.github.io/PythonDataScienceHandbook/03.04-missing-values.html)\n* Leanne and Justin's [\"Data Cleaning in Python: the Ultimate Guide (2020)\"](https://towardsdatascience.com/data-cleaning-in-python-the-ultimate-guide-2020-c63b88bf0a0d)\n* John Sullivan's [\"Data Cleaning with Python and Pandas: Detecting Missing Values\"](https://towardsdatascience.com/data-cleaning-with-python-and-pandas-detecting-missing-values-3e9c6ebcf78b)\n\nFor reference:\n  * Matthew Brem's [summary of statistical pros and cons of different missing values methods](https://github.com/matthewbrems/ODSC-missing-data-may-18/blob/master/Analysis%20with%20Missing%20Data.pdf).\n\nBefore class:\n* Follow the steps of Leanne and Justin's [\"Data Cleaning in Python: the Ultimate Guide (2020)\"](https://towardsdatascience.com/data-cleaning-in-python-the-ultimate-guide-2020-c63b88bf0a0d) tutorial, up to but not including the \"Irregular data (Outliers)\" section.\n\nIn class:\n* Together follow the steps of and create notes on John Sullivan's [\"Data Cleaning with Python and Pandas: Detecting Missing Values\"](https://towardsdatascience.com/data-cleaning-with-python-and-pandas-detecting-missing-values-3e9c6ebcf78b) tutorial.\n\nHomework after class:\n* Complete the section labeled \"Homework\" below before the next class when it will be collected.\n","pos":0,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"576835","input":"# In Class\n\nIn class, review John Sullivan's [\"Data Cleaning with Python and Pandas: Detecting Missing Values\"](https://towardsdatascience.com/data-cleaning-with-python-and-pandas-detecting-missing-values-3e9c6ebcf78b) together and create interleaved Markdown and Code cells below that **summarize main points** and **follow the programmatic steps** of the tutorial.  Seek to distill the tutorial to a concise summary in your own words (as I have, but will not supply here).\n\nTo make it easier to access, I've made John Sullivan's tutorial data available at [http://cs.gettysburg.edu/~tneller/ds256/data/missing/sullivan_property_data.csv](http://cs.gettysburg.edu/~tneller/ds256/data/missing/sullivan_property_data.csv).\n\nThis short tutorial focuses on which missing values are recognized by Pandas, how you can define others, and reviews some of the points of the previous tutorial.\n\n**IMPORTANT: The tutorial uses Python 2, so in order to adapt the code for our Python 3, you must add parentheses to print statements.  Also note that Pandas read_csv now recognizes more values as NaN/null.**","pos":5,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"64ff77","input":"_(From this point onward, copy the code sections of the tutorial. Before each Python cell, create a Markdown cell that explains what the code is for.  In doing so, you will digest the significance of the examples and provide notes you can return to in order to guide application of the techniques.)_","pos":4,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"71c444","input":"_(From this point onward, copy the code sections of the tutorial. Before each Python cell, create a Markdown cell that explains what the code is for.  In doing so, you will digest the significance of the examples and provide notes you can return to in order to guide application of the techniques.)_","pos":7,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"77a0bd","input":"(_Write your Exercise 2 answers here._)","pos":11,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"975f68","input":"# Data Cleaning: Missing Data\n\nA large proportion of a Data Scientists work is _data cleaning_, that is preparing data so that it is ready for modeling.  This includes dealing with missing data (e.g. someone declines to answer income on a survey), outliers (e.g. an entry in millimeters rather than meters), reducing to a common representation (e.g. accounting for synonyms), and other challenges that require the Data Science to _understand_ the data, and programmatically prepare it for modeling.\n\nIn this lesson, we focus on the challenge of _missing data_.  Interestingly, there is no simple, agreed-upon recipe for handling missing data.  If one has much good quality data, one might simply drop all rows with missing data.\n\nHowever, the data that is missing can also tell a story.  A person declining to answer a survey question can carry important information.  Silence can be informative, so explicitly creating a \"_missing_\" categorical value, or a \"sentinel\" numeric value outside the normal range of values, or a separate feature _flagging_ the prior numeric column as having a missing value, is a way of _embracing_ missing data and letting it remain missing.\n\nFurther, it is sometimes possible to \"fill in the blanks\".  This is called _imputation_ of missing values, and it must be practiced with care.\n\nWARNING: In our readings, it is suggested that one should impute the mean or median for missing values.  While often practiced, this is considered statistically invalid, as it effectively reduces the variance of the data.   It is better to build a predictor of missing values from the other data.  From the supplemental presentation slides above, you will see that there are even more sophisticated ways that do not bias the data.\n\nThat said, there is no perfect methodology.  This is why understanding the data and understanding your intended modeling is of greatest importance.  The first will guide a common sense approach for whether one should prefer to drop, embrace, or impute missing data.  The second will constrain the prior choices based on the flexibility of the modeling method.  For example, whereas decision-tree-based methods can sometimes handle missing values, neural networks cannot.\n\nAs we work our way to the end of the course, students will start to create more of their notebooks, as **this will be a key way for you to learn beyond this course**.\n\n## TO-DO: Before Class\n\nWhile reading Leanne and Justin's [\"Data Cleaning in Python: the Ultimate Guide (2020)\"](https://towardsdatascience.com/data-cleaning-in-python-the-ultimate-guide-2020-c63b88bf0a0d), create interleaved Markdown and Code cells below that **summarize main points** and **follow the programmatic steps** of the Missing Values portion.  Seek to distill that portion of the tutorial to a concise summary in your own words (as I have, but will not supply here).\n\nTo make it easier, I've made the tutorial data available at [http://cs.gettysburg.edu/~tneller/ds256/data/missing/sberbank.csv](http://cs.gettysburg.edu/~tneller/ds256/data/missing/sberbank.csv).  The tutorial data is directly from the [Kaggle Sberbank Russian Housing Market Competition](https://www.kaggle.com/c/sberbank-russian-housing-market), and one can read a [description of the data columns](https://www.kaggle.com/c/sberbank-russian-housing-market/data) there in file ```data_dictionary.txt```.\n","pos":2,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"9ceef1","input":"## Homework\n","pos":9,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"a53c0b","input":"**Exercise 1:** Complete the in-class exercise if you haven't already.\n\n**Exercise 2:** (Written question)\n\n1. Skim the [first place winner discussion](https://www.kaggle.com/c/sberbank-russian-housing-market/discussion/35684) on the [Kaggle Sberbank Russian Housing Market Competition](https://www.kaggle.com/c/sberbank-russian-housing-market).  What seemed most important to the success of their approach?\n\n2. Find a good Kaggle notebook on the [Kaggle Sberbank Russian Housing Market Competition](https://www.kaggle.com/c/sberbank-russian-housing-market) and provide a link to it.  Beyond missing values, in what respects was data cleaning necessary?\n\n3. Google search on keywords like \"Kaggle\", \"Sberbank\", and \"missing values\".  What do competitors have to say about how they worked with the missing values?  Which type of modeling algorithm was most commonly used to embrace and work directly with missing values?\n\nNote: There were many competitors working with the R programming language.  While the syntax is strange, you should be able to guess what they're doing in many cases based on our doing similar things in Python.","pos":10,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"a793f8","input":"**Optional In-Class Exercise:**\n\nSurvey which machine learning algorithms are able to handle missing values without the need to drop/impute them before model building.  List them below, noting popular Python implementations as appropriate.\n\n_(Enter your answers here.)_","pos":8,"state":"done","type":"cell"}
{"id":0,"time":1605143228258,"type":"user"}
{"last_load":1605079108817,"type":"file"}