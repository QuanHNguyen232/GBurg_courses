{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# An Introduction to Kaggle\n",
    "\n",
    "Learning Objectives:\n",
    "* Students will learn about the [Kaggle website](https://www.kaggle.com/) as a significant Data Science community resource for learning.\n",
    "* Students will create Kaggle accounts and sample offering of the site.\n",
    "* Students will configure their CoCalc accounts for the \"kaggle\" command and learn the commands necessary to engage in Kaggle competitions.\n",
    "\n",
    "Before class:\n",
    "* Read [elitedatascience.com's \"The Beginner's Guide to Kaggle\"](https://elitedatascience.com/beginner-kaggle)  _Read this for perspective and wise tips on how to best leverage the platform for your preparation for and lifelong learning of Data Science work._\n",
    "* Read below up to (but not including) the section marked In Class.  **Perform listed tasks and supplemental reading as directed below.**\n",
    "\n",
    "In class:\n",
    "* We will work together to make sure everyone's CoCalc account is correctly configured for engaging in Kaggle competitions.\n",
    "\n",
    "Homework after class:\n",
    "* Complete the section labeled \"Homework\" below before the next class when it will be collected.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# About Kaggle\n",
    "\n",
    "While [not the only Data Science competition website](https://towardsdatascience.com/top-competitive-data-science-platforms-other-than-kaggle-2995e9dad93c), Kaggle quickly became the best-known when it began offering Machine Learning competitions in 2010.  It quickly grew to become a hub of communication, learning, and practice for the Data Science community, which can partly be attributed to the incentives for community recognition offered on the site.  Recognition is given in the form of virtual medals which contribute towards [Kaggle Progression System](https://www.kaggle.com/progression) ranks of Novice, Contributor, Expert, Master, and Grandmaster for contribution in each of four areas: Competitions, Notebooks, Datasets, and Discussion.  Whereas competition medals are earned by good performance in Kaggle competitions, notebook, dataset, and discussion contributions are recognized by community upvotes.  Further, competitors are often required to share and explain their competition work for others to learn from.  This recognition system thus provides incentives for those seeking to distinguish themselves (e.g. to potential employers/clients) to provide helpful contributions to the community in exchange for such public recognition and third-party validation of expertise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## To-Do: Create Your Own Kaggle Account\n",
    "* Create your own account on [Kaggle.com](https://www.kaggle.com/).  We will be using this site occasionally, and you will find that it is an excellent supplemental resource in and beyond this class.\n",
    "* After registering your account, you will be ranked as a \"Novice\".  Advancement to \"Contributor\" status requires 9 steps of which you should _perform the first 5_:\n",
    "  * **Add a bio to your profile** (This need not be anything more than a sentence or two.)\n",
    "  * **Add your location** (e.g. \"Gettysburg, Pennsylvania, United States\")\n",
    "  * **Add your occupation** (e.g. \"student of Data Science at Gettysburg College\")\n",
    "  * **Add your organization** (e.g. \"Gettysburg College\")\n",
    "  * **SMS verify your account** (If you cannot SMS verify with your smartphone, contact Kaggle's Support team: support@kaggle.com)\n",
    "  * Run 1 script (optional for now)\n",
    "  * Make 1 competition or task submission (optional for now)\n",
    "  * Make 1 comment (optional for now)\n",
    "  * Cast 1 upvote (optional for now)\n",
    "\n",
    "Many use their Kaggle account not only to improve their Data Science problem solving skills, but to market those skills as well.  You may wish to further your learning and signal your growing expertise through your account going forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Kaggle Competitions\n",
    "\n",
    "Much activity in Kaggle centers around Kaggle Competitions.  As noted in the preparatory reading, Data Science as practiced on Kaggle differs from real-world Data Science work in a number of ways. Real-world problems may be easy, novel solutions may not be necessary, and humans often [satisfice](https://en.wikipedia.org/wiki/Satisficing) rather than optimize, i.e. balance efficiency and quality towards achieving \"good enough\" rather than expending inordinate energy to rank \\#1 for a Data Science task.  Nonetheless, Kaggle's challenging competitions, for both the competitor and observer, highlight the best in Exploratory Data Analysis, feature engineering, model-building algorithms, and insightful interpretation of data.  For those who do, who explain, and who provide insightful comment, these events provide ways for practioners to learn through the experiences.\n",
    "\n",
    "* **Read the current list of [Active Kaggle Competitions](https://www.kaggle.com/competitions).**\n",
    "\n",
    "You will note that some competitions are designated as ongoing \"Knowledge\" competitions.  These provide starting points for beginners.  Take a look at the [Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic) knowledge competition and read the documentation enough to understand what data is provided and what the competition model is expected to predict from such data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Kaggle Notebooks\n",
    "\n",
    "In addition to earning recognition for competition results, Kaggle members also earn recognition by providing high quality Jupyter notebooks that provide both explanation and code to teach others how to approach problems.   A notebook may be recognized for providing great instructive value, even if the competition results achieved by the approach are not among the top competitors.\n",
    "\n",
    "**To-Do**\n",
    "* Click on the [Notebooks](https://www.kaggle.com/notebooks) tab in Kaggle.\n",
    "* In the Public tab in the text field \"Search notebooks\", type \"titanic\" and press Enter to search Titanic notebooks, sorted by \"Most Votes\", i.e. upvotes.\n",
    "* Create a web link at the bottom of this cell to the most upvoted Titanic notebook and one other Titanic notebook of your choice that you browse and think may be helpful in aiding your learning and work in the future.\n",
    "\n",
    "I will provide an example link to a very insightful Titanic notebook illustrating Exploratory Data Analysis:\n",
    "* [EDA To Prediction (DieTanic)](https://www.kaggle.com/ash316/eda-to-prediction-dietanic/notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Kaggle Datasets\n",
    "\n",
    "Kaggle is also a source of many good public datasets.  Suppose you would like to do a course cluster project at Gettysburg College.  You might search Kaggle's dataset for keywords of interest, and you just might find the ideal dataset for combining your enjoyment of Data Science with application to the topic area of another course.\n",
    "\n",
    "**To-Do**\n",
    "* Click on the [Data]() tab in Kaggle.\n",
    "* Create a link at the bottom of this cell to the most upvoted public dataset.\n",
    "* Search keywords for a topic of interest to you and create a second link at the bottom of this cell to that dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Kaggle Discussions\n",
    "\n",
    "Finally, Kaggle recognizes good contributors to discussion.  This is a community that engages with each other, and not merely a platform to broadcast performance, notebooks, and datasets.  A good discussion contributor can aid others as well.  For example, whereas most Kaggle members use Python or R in their notebooks for competitions, [this Titanic discussion entry](https://www.kaggle.com/c/titanic/discussion/28323) shares the author's attempt to use Microsoft Excel to craft a competition entry.  Other discussion contributors [raise moral or ethical questions](https://www.kaggle.com/c/dstl-satellite-imagery-feature-detection/discussion/26684)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**To-Do:** Before class, make sure you use [this link](https://www.kaggle.com/t/0175eb2fe60940b68d3195eb893691c2) to gain access to my Kaggle In-Class test competition.  We will work together in class to make sure each person has success in configuring CoCalc to allow you to engage in Kaggle competitions.  (I would advise that you only take part at this point in Learning competitions with small datasets so as to not overrun your CoCalc account limits.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# In Class\n",
    "\n",
    "Together in class, we will:\n",
    "* Install the ```kaggle``` shell command in your CoCalc environment,\n",
    "* Configure the ```kaggle``` command to connect to your Kaggle account,\n",
    "* Download test competition data,\n",
    "* Compute a test competition submission, and\n",
    "* Submit an entry to the test competition.\n",
    "\n",
    "After class, you will download data for a different test competition and go through a prescribed process for submitting to that competition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In the same folder as this notebook, go to \"+ New\" and create a new \"kaggle.x11\" X11 Desktop.  This creates what is known as a Linux command shell window in the upper left with command prompts ending in \"$\".  After each prompt, the user can type a command that your virtual Linux computer on CoCalc (a Linux Docker container for those interested) will execute, print any output, and give you another prompt.  Like Python, IPython, and other interpreter environments, this is what is referred to as a read-eval-print loop.\n",
    "\n",
    "Enter the following commands:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "pip install kaggle\n",
    "which kaggle\n",
    "mkdir ~/.kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The first command seeks to install the kaggle Linux command.  The second checks to see where the command is installed.  The third creates a directory to put your Kaggle account key into for identifying you as the user of the command.  \n",
    "\n",
    "Now from a Kaggle page where you are logged in, left-click your user symbol and select \"My Account\".  Under your Kaggle account, there is an \"API\" section where you can click a button \"Create New API Token\".  Download the \"kaggle.json\" file to your computer and then upload it to this Kaggle folder.  We will then move the file into the correct folder with correct access permissions with the following commands entered in your \"kaggle.x11\" tab's shell:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "mv kaggle.json ~/.kaggle/\n",
    "chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "At this point, your ```kaggle``` shell command should work.  To get the test competition data, enter the commands to download and unzip the competition files:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "kaggle competitions download -c inclass-competition-test\n",
    "unzip inclass-competition-test.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now we should have the competition data and be able to work with it as with the initial linear regression demo.  Take a moment to review the competition link and read about the different files you have downloaded and unzipped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Using Our Linear Regression to Predict for Kaggle Contest ```test.csv```\n",
    "\n",
    "In this next code block, we illustrate how to read test data (without the ```y``` output), using our linear regression to predict the output, adding these predictions to our dataframe, how to _output CSV_ predictions, and how to submit them to our Kaggle competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id        x1        x2        x3           y\n",
      "0   0  0.013024 -0.376194 -0.156695   31.638628\n",
      "1   1  0.295720  0.304128 -0.378602 -202.152690\n",
      "2   2  0.539952 -0.162594 -0.427334 -194.812320\n",
      "3   3 -0.372273 -0.003075  0.491478  374.543182\n",
      "4   4 -0.049420  0.365024 -0.331134 -224.375438\n",
      "     id        x1        x2        x3\n",
      "0  5000 -0.315663 -0.402388  0.150085\n",
      "1  5001  0.200608 -0.414422 -0.418825\n",
      "2  5002  0.148022 -0.508669 -0.144411\n",
      "3  5003  0.046422 -0.293633  0.257899\n",
      "4  5004  0.288848  0.310982 -0.446483\n",
      "     id           y\n",
      "0  5000  176.376392\n",
      "1  5001 -254.353860\n",
      "2  5002  -38.414781\n",
      "3  5003  277.488843\n",
      "4  5004 -271.907152\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Load the comma-separated values training data \"train.csv\", i.e. data with input(s) and output(s),\n",
    "# and create a dataframe of the data:\n",
    "data_path = \"./\"   # This means \"Look in the current directory for the file.\"\n",
    "df_train = pd.read_csv(data_path + 'train.csv')\n",
    "\n",
    "# Let's look at the \"head\", the initial rows, of the training data dataframe:\n",
    "print(df_train.head())\n",
    "\n",
    "# We can see that there's an identifier index \"id\", but what concerns us for this exercise are\n",
    "# the inputs \"x1\", \"x2\", and \"x3\" and the output \"y\".\n",
    "# As before, we separate these into separate data frames and use these to compute our linear regression model:\n",
    "X = df_train[['x1', 'x2', 'x3']]\n",
    "y = df_train[['y']]\n",
    "linear_regressor = LinearRegression()\n",
    "linear_regressor.fit(X, y)\n",
    "\n",
    "# Next we load our test data:\n",
    "df_test = pd.read_csv(data_path + 'test.csv')\n",
    "\n",
    "# Print the \"head\" of the test data, and show that it has all of what's in train.csv except for the output y column:\n",
    "print(df_test.head())\n",
    "\n",
    "# Now we can separate out the inputs of our test data and create a new df_test dataframe column 'y'\n",
    "# that we assign our linear regression predictions to:\n",
    "X = df_test[['x1','x2','x3']]\n",
    "df_test['y'] = linear_regressor.predict(X)\n",
    "\n",
    "# The contest submission format is a CSV file that only has the \"id\" and \"y\" columns, so we create a submission\n",
    "# dataframe \"df_submission\" with just those columns from df_test, print the first few rows to verify the\n",
    "# contents of our submission, and then write the output to a new CSV file \"submission.csv\" in this folder/directory.\n",
    "df_submission = df_test[['id','y']]\n",
    "print(df_submission.head())\n",
    "df_submission.to_csv(path_or_buf=open(data_path + 'submission.csv', 'w+'), index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now switch to your X11 terminal window and submit ```submission.csv``` to the competition with the command:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "kaggle competitions submit -c inclass-competition-test -f submission.csv -m \"my first CoCalc submission\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "After ```-c``` is the short competition code name.  After ```-f``` is your submission filename.  After ```-m``` is a message you add to tell apart your different submissions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Homework\n",
    "\n",
    "For this homework, your single exercise is to compete in our practice [Linear Regression: Signal and Noise](https://www.kaggle.com/c/inclass-signal-and-noise) Kaggle competition for which you may need to gain access to through [this link](https://www.kaggle.com/t/210dd01c1a734f78a31c89e2ce5d6db5).\n",
    "\n",
    "To get best results, examine the data input/output correlation and only perform linear regression using correlating inputs.  Go through the same steps as above.  Perform correlation visualization as we did in our first linear regression demo.  Remember that you'll use the contest code ```inclass-signal-and-noise``` rather than our previous contest code ```inclass-competition-test```.\n",
    "\n",
    "A perfect rating will be achieved by clearly performing all steps and achieving the benchmark contest score.\n",
    "\n",
    "**Note: To avoid overwriting your previous contest files of the same name, use these two commands:**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "kaggle competitions download -c inclass-signal-and-noise\n",
    "unzip inclass-signal-and-noise.zip -d hw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Next, you'll need to reassign ```file_path``` to the value ```'hw/'``` before loading the files.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "When you are done, if you have written your ```submission.csv``` to that same ```hw``` directory, you'll need to modify your ```kaggle``` submission command accordingly:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "kaggle competitions submit -c inclass-signal-and-noise -f hw/submission.csv -m \"my first signal and noise submission\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (system-wide)",
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python 3 programming language",
     "priority": 100,
     "url": "https://www.python.org/"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}